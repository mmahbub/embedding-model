{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28930a-8b8b-44e6-8097-c99375bf37c9",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370e0d2-1e9c-417f-9387-e28a5f090475",
   "metadata": {},
   "source": [
    "In this notebook, we finetune an opensource sentencetransformers embedding model on our synthetically generated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6340211a-db64-458f-b3fb-4b87f09ab743",
   "metadata": {},
   "source": [
    "### Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd53aa4c-b83b-41a3-9b73-498aca71e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/75y/.conda/envs/mrc_meth/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70df8f69-9d40-4467-9755-5582b4ca5178",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = \"BAAI/bge-large-en-v1.5\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3502aaba-3e8a-42a6-9665-9d59304e798b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd0ab4-6687-4b54-aff7-b30aa96f3698",
   "metadata": {},
   "source": [
    "### Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad17db1-e4b6-4c54-9242-905fb9cd9451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/75y/.conda/envs/mrc_meth/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import InputExample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "368c70ef-58d7-4242-97c5-ac9c5811e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/75y/data_ragMimic/data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e26aa72e-c158-4d6c-862f-bb555e5e456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_FPATH = DATA_PATH+'train_dataset.json'\n",
    "VAL_DATASET_FPATH = DATA_PATH+'val_dataset.json'\n",
    "\n",
    "# We use a very small batchsize to run this toy example on a local machine. \n",
    "# This should typically be much larger. \n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2713df64-b708-48f9-8a0a-505ee24ec381",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_DATASET_FPATH, 'r+') as f:\n",
    "    train_dataset = json.load(f)\n",
    "\n",
    "with open(VAL_DATASET_FPATH, 'r+') as f:\n",
    "    val_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07e006a-9a08-4961-b639-66a7a65bc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = train_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "examples = []\n",
    "for query_id, query in queries.items():\n",
    "    node_id = relevant_docs[query_id][0]\n",
    "    text = corpus[node_id]\n",
    "    example = InputExample(texts=[query, text])\n",
    "    examples.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7b7f2f2-0012-4ec7-8f44-1909d42c84b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    examples, batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbfdb60-610f-4847-b9a2-498c703b951a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': '',\n",
       " 'texts': [\"What was the patient's discharge diagnosis?\",\n",
       "  'they recommended  sling for the l arm and follow up in their clinic in 2 weeks.  \\nhis pain was well controlled with tylenol alone.  he was doing  well and was discharged to home.  he was instructed to stop his \\neliquis until he sees his cardiologist.  \\n \\nmedications on admission: eliquis\\nbactrim \\n \\ndischarge medications: bactrim\\n \\ndischarge disposition: home\\n \\ndischarge diagnosis: 1. s/p motor vehicle collision\\n2. displaced comminuted left clavicle fx\\n3. right abdominal wall hematoma\\n4. l5 right transverse process fx\\n\\n \\ndischarge condition: mental status: clear and coherent.\\nlevel of consciousness: alert and interactive.\\nactivity status: ambulatory - independent.\\n\\n \\ndischarge instructions: you came to the hospital after a car accident.  you were found  to have a broken left collarbone, a broken piece of bone in your  low back, and a blood collection in your right abdomen.  you  were monitored overnight to ensure there was no evidence of  continued bleeding.  your blood counts decreased initially but  were stable on repeat lab work.  you were discharged to home in  stable condition.  you should not restart your eliquis unless  told to do so by your cardiologist.  you should keep your left  arm in the sling until told otherwise by the orthopedic surgeons  at your follow up appointment.  you may take tylenol for the  pain.  you should take no more than 3,000mg of tylenol per day.\\n \\nfollowup instructions: ___'],\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples[-2].__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8acef2-8618-4afa-84e0-cd959d181208",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d643c3f-563a-44ae-a4aa-6a5fd8780ff9",
   "metadata": {},
   "source": [
    "**MultipleNegativesRankingLoss** is a great loss function if you only have positive pairs, for example, only pairs of similar texts like pairs of paraphrases, pairs of duplicate questions, pairs of (query, response), or pairs of (source_language, target_language).\n",
    "\n",
    "This loss function works great to train embeddings for retrieval setups where you have positive pairs (e.g. (query, relevant_doc)) as it will sample in each batch n-1 negative docs randomly.\n",
    "\n",
    "The performance usually increases with increasing batch sizes.\n",
    "\n",
    "For more detals, see:\n",
    "* [docs](https://www.sbert.net/docs/package_reference/losses.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd4e6b0f-8ffd-4f40-bbc8-bb307c32e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "928eec1f-0f47-4bac-9189-7b791e81024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044745-c271-40b3-a6d9-dd646ab281de",
   "metadata": {},
   "source": [
    "### Define evaluator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa016f4-ede5-4cfa-94d1-2449321a6ac8",
   "metadata": {},
   "source": [
    "We setup an evaluator with our val split of the dataset to monitor how well the embedding model is performing during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4cb4df8-d12b-4956-85d5-447a24331cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import InformationRetrievalEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64ab1591-ce7e-4990-a708-9b22a7ce0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = val_dataset\n",
    "\n",
    "corpus = dataset['corpus']\n",
    "queries = dataset['queries']\n",
    "relevant_docs = dataset['relevant_docs']\n",
    "\n",
    "evaluator = InformationRetrievalEvaluator(queries, corpus, relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5deb95-6d9a-4da8-ba46-f0317b12d6df",
   "metadata": {},
   "source": [
    "### Run training "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec69ca-21b0-4005-9e62-aef1393c4e6d",
   "metadata": {},
   "source": [
    "The training loop is very straight forward to steup thanks to sentencetransformers' high-level model training API.\n",
    "All we need to do is plugging in the data loader, loss function, and evaluator that we defined in the previous cells (along with a couple of additional minor settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ff9b09-c191-4ac0-a89e-629031e648d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We train the model for very few epochs in this toy example.\n",
    "# This should typically be higher for better performance.\n",
    "EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b6afdf-87d6-40be-b6fd-36f89dbb3612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba2811e17464ab980aeda6dd25b6117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59611d1e5861487e917f8ceb5a9551c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/6157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b481fc7a6c946d495470e697c648e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/6157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca0276fdddd493285b79073c72563a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/6157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = int(len(loader) * EPOCHS * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=EPOCHS,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path='exp_finetune',\n",
    "    show_progress_bar=True,\n",
    "    evaluator=evaluator, \n",
    "    evaluation_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6304d1f-aecf-42ff-9852-03f49bde8f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
